{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "28445d0f-ccac-4a52-96de-833927f95700",
        "_uuid": "dd46d2f885afef3adeb862468e3bc7834852c11a"
      },
      "cell_type": "markdown",
      "source": "*Hello everyone, this is my first Kernel and I'm very motivated to work on this project! ***\n\n# **Introduction** : sngrams\n\nIn this tutorial, we will try to use the**  [#SNGRAMS ](https://pdfs.semanticscholar.org/4e5a/778e0e45a4bddb81916a33d8e3b380fbb836.pdf) **to find which author wrote which sentences ! Grigori Sidorov, Francisco Velasquez, Efstathios Stamatatos, Alexander Gelbukh and Liliana Chanona did the same research with the same number of authors : THREE ! Strange, isn't it ? \n\n# ** 1. What are sngrams ? **\n##  1.1. Stanford Parser\n\nSyntactic N-grams are using the output of the ** [ #Stanford Parser](http://nlp.stanford.edu:8080/parser/) ** which is a probabilistic parser that use knowledge of language. The parser exists in English and extrats groups of words that have a grammatical relation. The model is based on the structure of the sentences which depends of the language. \n\nThe output of this parser for a sentence like ' It never once occurred to me that the fumbling might be a mere mistake.' (which is the second sentence of our train set) would look like : \n\nnsubj(occurred-4, It-1)<br>\nneg(occurred-4, never-2)<br>\nadvmod(occurred-4, once-3)<br>\nroot(ROOT-0, occurred-4)<br>\ncase(me-6, to-5)<br>\nnmod(occurred-4, me-6)<br>\nmark(mistake-14, that-7)<br>\ndet(fumbling-9, the-8)<br>\nnsubj(mistake-14, fumbling-9)<br>\naux(mistake-14, might-10)<br>\ncop(mistake-14, be-11)<br>\ndet(mistake-14, a-12)<br>\namod(mistake-14, mere-13)<br>\nccomp(occurred-4, mistake-14)<br>\n\nThe following tree is also defined :\n![](https://raw.githubusercontent.com/BoltMaud/Kaggle_images/master/graphstanford.bmp)\n\n*This graphe was designed by the librairy : nltk.draw.tree. * \n*The name 'nsubj', 'neg' .. is the relation between the words in the parenthesis. The number indicates the position of the words in the sentence.   \n\n## 1.2. n-grams using the stanford parser\n\n### 1.2.1 Normal n-grams\nUsing the sentence 'It never once occurred to me that the fumbling might be a mere mistake' the normal 2-grams is : \n\nIt never ;  never once ;  once occurred ; occured to ;  to me ; me that ;  that the ;  the fumbling ; fumbling might ; might be ; be a ; a mere ;  mere mistake\n\nFor a 3-grams : \n\nIt never once ;never once occurred ; once occurred to ; occurred to me ;to me that ; me that the ;that the fumbling ;the fumbling  might ; fumbling  might be ; might be a ; be a mere ; a mere mistake\n \n ### 1.2.2 Sn-grams \n The sn-grams use the result of the stanford parser and gives :\n \n For a s2grams, the couples are all the couple from the roots :\n occured once, occured never, occured it , occured to, occured mistake, mistake mere,mistake a, mistake be, mistake might, mistake fumbling, mistake that, fumbing the, me to \n \n For a s3grams the (occured to) and (to me) become (occured to me) and (mistake fumbling) and (fumbling the) become (mistake fumbling the) \n \n # ** 2. How to use sngrams **\n \n I tried this solution on my computer but to generate all the features, the programme needed 5 hours. I decided to try without the syntaxic ngrams.\n \n # ** 3. Programme with ngrams ** \n \n "
    },
    {
      "metadata": {
        "_cell_guid": "261e93f5-1dda-4811-8e8b-95ef455ea184",
        "_uuid": "889c9f81b2c443189cf620602ce412bf2b636c5e"
      },
      "cell_type": "markdown",
      "source": "First, we import the dataset and the libs : "
    },
    {
      "metadata": {
        "_cell_guid": "7195c9b3-7782-4fe9-81f7-c382a75ad7f9",
        "collapsed": true,
        "_uuid": "64e544ad7f624a97c71f2292d4047f3a77e28b53",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nimport pandas as pd\n\ndfTrain = pd.read_csv(\"../input/train.csv\") # importing train dataset\ndfTest = pd.read_csv(\"../input/test.csv\") # importing test dataset",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "84de8e9c-82b7-498a-b6a8-b1e43ed3b224",
        "_uuid": "e08ac651131e14a854fe74aa5a25bba2fb290d08"
      },
      "cell_type": "markdown",
      "source": "Then we create a matrix with the ngrams using TiDf. We delete the stop-word and accepte ngrams from 1 word to 3. \nThe function fit_tranform will tranform the data into a matrix and fit the model. "
    },
    {
      "metadata": {
        "_cell_guid": "a83ba9cd-9494-4138-8835-146159468137",
        "collapsed": true,
        "_uuid": "c92344023b091ee0491b31716b3987b6c3c37a92",
        "trusted": false
      },
      "cell_type": "code",
      "source": "vectorizer = CountVectorizer(stop_words=\"english\",analyzer='word', ngram_range=(1,3))\ntrain_counts = vectorizer.fit_transform(dfTrain.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "237b16d3-7a13-4244-b8e8-de91fe2c88e1",
        "_uuid": "7717f4a39bc5b82ff9668ff62df17ecb465f00e8"
      },
      "cell_type": "markdown",
      "source": "We fit the model with the Multinomiale method because it's the best one for the problems using TiDf and ngrams."
    },
    {
      "metadata": {
        "_cell_guid": "eb638e63-872d-415a-9208-257f052e383e",
        "collapsed": true,
        "_uuid": "b6b673f252d80c78efd61c310db9852cbbe4b697",
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier = MultinomialNB()\nclassifier.fit(train_counts, dfTrain.author)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fdf46071-772a-4db4-add6-0d671f523096",
        "_uuid": "78fcda81b5061764ad9dcbcab843710059d6021b"
      },
      "cell_type": "markdown",
      "source": "The test set need to be transform too and the model is ready to predict : "
    },
    {
      "metadata": {
        "_cell_guid": "90d1c01b-bb55-4633-851b-f325a64a6e49",
        "collapsed": true,
        "_uuid": "20cff2c59b1cfa37c422bf1a76746eb189c59761",
        "trusted": false
      },
      "cell_type": "code",
      "source": "tests_counts = vectorizer.transform(dfTest.text)\npredicted = pd.DataFrame(classifier.predict_proba(tests_counts) )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3e9c82db-3b44-4d2f-a278-5c7c3abc52e0",
        "_uuid": "93dd7bc285a9678c555bd3f08d5874af9ad82d1a"
      },
      "cell_type": "markdown",
      "source": "Finally, we prepare the submit file :"
    },
    {
      "metadata": {
        "scrolled": true,
        "_cell_guid": "8df0b583-8633-4513-8576-250632f30cf7",
        "_kg_hide-output": false,
        "collapsed": true,
        "_uuid": "1990aefc7571f7d7044c2ab90293d04c27eb8ae6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submit=pd.DataFrame({})\nsubmit[\"id\"]=dfTest.id\nsubmit[\"EAP\"]=predicted[0]\nsubmit[\"HPL\"]=predicted[1]\nsubmit[\"MWS\"]=predicted[2]\n\nprint(submitfinal)\nsubmit.to_csv(\"submit.csv\", sep=',',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e4787ed4-68c1-41e2-9ab7-8478c4613d05",
        "_uuid": "53645af1ac21c88e31a9aeaafc7162e1bd50eca0"
      },
      "cell_type": "markdown",
      "source": "# ** 4. Vizualisation ** \n\nIn this part, I'm not sure to keep the rules but I didn't see anything that forbidd to use everything we know. \n\n## 4.1 LDA Vizualisation \n\nFirstly, I used knime to extract the words topics for each authors. I created a vizualisation with the colors of Halloween. The size of a word depend of its weight at the output of LDA algorithm. \n\n![](https://raw.githubusercontent.com/BoltMaud/Kaggle_images/master/viz1.png)\n\nThen I used [#Tropes](http://www.tropes.fr/) to get some interesting information about the grammar.\n\n** THE PRONOUNS **\n![](https://raw.githubusercontent.com/BoltMaud/Kaggle_images/master/pronouns.png)\n\n** THE CONNECTORS **\n![](https://raw.githubusercontent.com/BoltMaud/Kaggle_images/master/connectors_.png)\n\n** THE MODALIZATION ** \n![](https://raw.githubusercontent.com/BoltMaud/Kaggle_images/master/modalities_.png)\n\n\n\n"
    }
  ],
  "metadata": {
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.6.3",
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}